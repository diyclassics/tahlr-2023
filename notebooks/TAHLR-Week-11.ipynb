{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAHLR Week 11: Word Embeddings\n",
    "\n",
    "Code notebook for TAHLR course at ISAW (Fall 2023) based on Albrecht et al. 2022 (Blueprints) Ch. 10: Exploring Semantic Relationships with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install plotly\n",
    "#!pip install umap-learn\n",
    "\n",
    "# Imports\n",
    "\n",
    "from glob import glob\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Using Similarity Queries on Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directory from gensim api\n",
    "import gensim.downloader as api\n",
    "\n",
    "info_df = pd.DataFrame.from_dict(api.info()['models'], orient='index')\n",
    "info_df[['file_size', 'base_dataset', 'parameters']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific model\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector size, etc.\n",
    "\n",
    "print(\"Vector size:\", model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show vectors\n",
    "\n",
    "v_king = model['king']\n",
    "v_queen = model['queen']\n",
    "\n",
    "print(\"v_king  =\", v_king[:10])\n",
    "print(\"v_queen =\", v_queen[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show similarity to two terms\n",
    "\n",
    "print(\"similarity:\", model.similarity('king', 'queen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show closest terms by similarity\n",
    "\n",
    "model.most_similar('king', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show relative similarity\n",
    "\n",
    "v_lion = model['lion']\n",
    "v_nano = model['nanotechnology']\n",
    "\n",
    "terms = ['queen', 'lion', 'nanotechnology']\n",
    "sims = model.cosine_similarities(v_king, [model[t] for t in terms])\n",
    "\n",
    "for term, sim in zip(terms, sims):\n",
    "    print(f\"king ~ {term:<15}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show similarity with negative terms\n",
    "\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show similarity with negative terms, 2\n",
    "model.most_similar(positive=['paris', 'germany'], negative=['france'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct \"positive\" approach\n",
    "\n",
    "model.most_similar(positive=['france', 'capital'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct \"positive\" approach, 2 (doesn't work\n",
    "\n",
    "model.most_similar(positive=['greece', 'capital'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Training Models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get texts, preprocess into sents\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "URL = \"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\"\n",
    "response = urllib.request.urlopen(URL)\n",
    "raw = response.read().decode('utf-8')\n",
    "sents = sent_tokenize(raw)\n",
    "sents = [sent.lower() for sent in sents if len(sent) > 20]\n",
    "sents = [word_tokenize(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of sents\n",
    "\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train w2v model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sents,       # tokenized input sentences\n",
    "                 vector_size=100,    # size of word vectors (default 100)\n",
    "                 window=5,    # context window size (default 5)\n",
    "                 sg=1,        # use skip-gram (default 0 = CBOW)\n",
    "                 negative=5,  # number of negative samples (default 5)\n",
    "                 min_count=3, # ignore infrequent words (default 5)\n",
    "                 workers=4,   # number of threads (default 3)\n",
    "                 epochs=5)      # number of epochs (default 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Create the directory if it doesn't exist\n",
    "# if not os.path.exists('../data/models'):\n",
    "#     os.makedirs('../data/models')\n",
    "\n",
    "# # Save the model\n",
    "# model.save('../data/models/shakespeare_w2v_100_5_full.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocab\n",
    "\n",
    "key_to_index = model.wv.key_to_index\n",
    "index_to_key = model.wv.index_to_key\n",
    "full_vocab = list(key_to_index.keys())\n",
    "print(full_vocab[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show closest terms by similarity\n",
    "\n",
    "model.wv.most_similar(positive=['romeo'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show closest terms by similarity, 2\n",
    "\n",
    "model.wv.most_similar(positive=['king'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show closest terms by similarity, 3\n",
    "model.wv.most_similar(positive=['fool'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show closest terms with negative term\n",
    "\n",
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Applying Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality\n",
    "\n",
    "from umap import umap_ as umap\n",
    "\n",
    "vocab = model.wv.index_to_key\n",
    "df = pd.DataFrame(model.wv.vectors, index=vocab)\n",
    "reduced_wv = embedding = umap.UMAP(random_state=42).fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced vectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1])\n",
    "plt.title('UMAP clustering of 4406 cells', fontsize=20)\n",
    "plt.xlabel('UMAP_1')\n",
    "plt.ylabel('UMAP_2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced vectors, explorative interface\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "plot_df = pd.DataFrame.from_records(reduced_wv, columns=['x', 'y'])\n",
    "plot_df['word'] = vocab\n",
    "params = {'hover_data': {c: False for c in plot_df.columns},\n",
    "          'hover_name': 'word'}\n",
    "\n",
    "fig = px.scatter(plot_df, x=\"x\", y=\"y\", opacity=0.3, size_max=3, **params)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced vectors, selective (uses custom script)\n",
    "\n",
    "from bp_embeddings import plot_embeddings\n",
    "\n",
    "search = \"goneril regan cordelia\".split()\n",
    "\n",
    "plot_embeddings(model, search, topn=10, show_all=False, labels=True,\n",
    "    algo='umap', n_neighbors=15, min_dist=10, spread=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced vectors, selective (uses custom script), 2\n",
    "\n",
    "from bp_embeddings import plot_embeddings\n",
    "\n",
    "search = \"goneril regan cordelia lear\".split()\n",
    "\n",
    "plot_embeddings(model, search, topn=10, show_all=False, labels=True,\n",
    "    algo='umap', n_neighbors=15, min_dist=10, spread=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced vectors, selective (uses custom script), 3\n",
    "\n",
    "from bp_embeddings import plot_embeddings\n",
    "\n",
    "search = \"goneril regan cordelia lear beatrice\".split()\n",
    "\n",
    "plot_embeddings(model, search, topn=10, show_all=False, labels=True,\n",
    "    algo='umap', n_neighbors=15, min_dist=10, spread=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Constructing a Similarity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import deque\n",
    "\n",
    "def sim_tree(model, word, top_n, max_dist):\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    graph.add_node(word, dist=0)\n",
    "\n",
    "    to_visit = deque([word])\n",
    "    while len(to_visit) > 0:\n",
    "        source = to_visit.popleft() # visit next node\n",
    "        dist = graph.nodes[source]['dist']+1\n",
    "\n",
    "        if dist <= max_dist: # discover new nodes\n",
    "            for target, sim in model.wv.most_similar(source, topn=top_n):\n",
    "                if target not in graph:\n",
    "                    to_visit.append(target)\n",
    "                    graph.add_node(target, dist=dist)\n",
    "                    graph.add_edge(source, target, sim=sim, dist=dist)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "def plot_tree(graph, node_size=1000, font_size=12):\n",
    "\n",
    "    pos = graphviz_layout(graph, prog='twopi', root=list(graph.nodes)[0])\n",
    "\n",
    "    colors = [graph.nodes[n]['dist'] for n in graph] # colorize by distance\n",
    "    nx.draw_networkx_nodes(graph, pos, node_size=node_size, node_color=colors,\n",
    "                           cmap='Set1', alpha=0.4)\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=font_size)\n",
    "\n",
    "    for (n1, n2, sim) in graph.edges(data='sim'):\n",
    "         nx.draw_networkx_edges(graph, pos, [(n1, n2)], width=sim, alpha=0.2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sim_tree(model, 'caesar', top_n=5, max_dist=3)\n",
    "plot_tree(graph, node_size=250, font_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tahlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
