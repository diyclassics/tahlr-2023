{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic collocations using CLTK Readers & NLTK\n",
    "[Patrick J. Burns](https://diyclassics.github.io), Institute for the Study of the Ancient World / NYU  \n",
    "11.9.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from cltkreaders.lat import LatinTesseraeCorpusReader\n",
    "# from latintools import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "# Helper function for preprocessing\n",
    "def preprocess(\n",
    "    text,\n",
    "    lower=True,\n",
    "    normalize=True,\n",
    "    punctuation=False,\n",
    "    numbers=False,\n",
    "    unhyphenate=False,\n",
    "    remove_lines=False,\n",
    "    remove_spaces=False,\n",
    "    entities=False,\n",
    "    diacriticals=True,\n",
    "    fill=\" \",\n",
    "):\n",
    "\n",
    "    import html\n",
    "    import re\n",
    "    import unicodedata\n",
    "    from cltk.alphabet.lat import JVReplacer\n",
    "\n",
    "    replacer = JVReplacer()\n",
    "\n",
    "    if not entities:\n",
    "        text = html.unescape(text)\n",
    "\n",
    "    if unhyphenate:\n",
    "        text = re.sub(r\"[-»—]\\s?\\n\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    if lower:\n",
    "        text = text.lower()  # Lowercase\n",
    "\n",
    "    if normalize:\n",
    "        text = replacer.replace(text)\n",
    "\n",
    "    if not punctuation:\n",
    "        # Remove punctuation\n",
    "        punctuation = \"\\\"#$%&'()*+,/:;<=>@[\\]^_`{|}~.?!«»—“-”\"\n",
    "        misc = \"¡£¤¥¦§¨©¯°±²³´µ¶·¸¹º¼½¾¿÷·–‘’†•ↄ∞⏑〈〉（）\"\n",
    "        misc += punctuation\n",
    "        translator = str.maketrans({key: fill for key in misc})\n",
    "        text = text.translate(translator)\n",
    "\n",
    "    if not numbers:\n",
    "        # Remove numbers\n",
    "        translator = str.maketrans({key: fill for key in \"0123456789\"})\n",
    "        text = text.translate(translator)\n",
    "\n",
    "    if remove_lines:\n",
    "        text = \" \".join(text.split(\"\\n\"))\n",
    "\n",
    "    if remove_spaces:\n",
    "        text = fill.join(text.split())\n",
    "\n",
    "    def remove_diacriticals(text):\n",
    "        combining_character_table = dict.fromkeys(\n",
    "            c for c in range(sys.maxunicode) if unicodedata.combining(chr(c))\n",
    "        )\n",
    "        text = unicodedata.normalize(\"NFD\", text)\n",
    "        text = text.translate(combining_character_table)\n",
    "        return text\n",
    "\n",
    "    if not diacriticals:\n",
    "        text = remove_diacriticals(text)\n",
    "\n",
    "    # Fix spacing\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get corpus reader\n",
    "\n",
    "T = LatinTesseraeCorpusReader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show bigram example from the cat\n",
    "\n",
    "cat = 'cicero.in_catilinam.tess'\n",
    "cat_sents = T.sents(cat)\n",
    "cat_sent = next(cat_sents).text\n",
    "print(cat_sent)\n",
    "cat_sent = preprocess(cat_sent)\n",
    "cat_bigrams = list(nltk.bigrams(cat_sent.split()))\n",
    "print(cat_bigrams[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram frequency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way for us to get a sense of which words tend to cooccur in Latin is to observe the phenomenon directly, that is we can create a list of all word pairs and report the highest frequency pairs. Using Cicero's *Brutus* as a test case, let's build this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up exploratory test\n",
    "# Get bigrams for Cicero's Brutus\n",
    "\n",
    "file = 'cicero.brutus.tess'\n",
    "words = list(T.words(file, preprocess=preprocess, plaintext=True))\n",
    "print(\" \".join(words[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bigrams for Cicero's Brutus\n",
    "\n",
    "bigrams = list(nltk.bigrams(words))\n",
    "print(bigrams[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make counter of bigrams\n",
    "\n",
    "bigrams_counter = Counter(bigrams)\n",
    "bigrams_top = bigrams_counter.most_common(10)\n",
    "bigrams_top_display = [(bigram, count) for bigram, count in bigrams_top]\n",
    "df_freq = pd.DataFrame(list(bigrams_top_display), columns=['bigram', 'count']).sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "df_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make counter of bigrams, with NLTK collocations approach\n",
    "\n",
    "# Create bigrams and Finder\n",
    "\n",
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "Finder = nltk.collocations.BigramCollocationFinder.from_words(words)\n",
    "Finder.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram frequency\n",
    "\n",
    "df_freq = pd.DataFrame(list(Finder.ngram_fd.items()), columns=['bigram', 'count']).sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "df_freq.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify \"meaningful\" bigrams using PMI\n",
    "\n",
    "df_pmi = pd.DataFrame(list(Finder.score_ngrams(bigrams.pmi)), columns=['bigram','PMI'])\n",
    "df_pmi = pd.merge(df_freq, df_pmi, on='bigram')\n",
    "df_pmi.sort_values(by='PMI', ascending=False).head(10).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify \"meaningful\" bigrams using Chi-squared\n",
    "\n",
    "df_chisq = pd.DataFrame(list(Finder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-sq'])\n",
    "df_chisq = pd.merge(df_freq, df_chisq, on='bigram')\n",
    "df_chisq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-likelihood ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify \"meaningful\" bigrams using log likelihood Ratio\n",
    "\n",
    "df_loglike = pd.DataFrame(list(Finder.score_ngrams(bigrams.likelihood_ratio)), columns=['bigram','likelihood ratio'])\n",
    "df_loglike = pd.merge(df_freq, df_loglike, on='bigram')\n",
    "df_loglike.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search collocation space\n",
    "\n",
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "Finder = nltk.collocations.BigramCollocationFinder.from_words(words)\n",
    "\n",
    "df_pmi = pd.DataFrame(list(Finder.score_ngrams(bigrams.pmi)), columns=['bigram','PMI'])\n",
    "df_pmi = pd.merge(df_freq, df_pmi, on='bigram')\n",
    "\n",
    "term = 'publica'\n",
    "\n",
    "brutus = df_pmi[df_pmi['bigram'].apply(lambda x: term in \" \".join(x))].sort_values(by='PMI', ascending=False).reset_index(drop=True)\n",
    "brutus.sort_values(by='PMI', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collocations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b84fef61d24d8da3e2cfa0b849fbe0873115cd820170594b5dea28cfbe20c8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
