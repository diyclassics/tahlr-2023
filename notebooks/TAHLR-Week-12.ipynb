{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAHLR Week 12: Sentiment analysis\n",
    "\n",
    "Code notebook for TAHLR course at ISAW (Fall 2023) based on Albrecht et al. 2022 (Blueprints) Ch. 11: Performing Sentiment Analysis on Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installs\n",
    "# ! pip install -U textacy\n",
    "# ! pip install -U transformers\n",
    "\n",
    "# Imports\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get data from remote location\n",
    "\n",
    "# !mkdir -p ../data/blueprints\n",
    "# !curl -LJO https://github.com/blueprints-for-text-analytics-python/blueprints-text/raw/master/data/amazon-product-reviews/reviews_5_balanced.json.gz --output-dir ../data/blueprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/blueprints/reviews_5_balanced.json.gz', lines=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Performing sentiment analysis using lexicon-based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words in opinion lexicon',\n",
    "      opinion_lexicon.positive()[:5])\n",
    "print('Examples of negative words in opinion lexicon',\n",
    "      opinion_lexicon.negative()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dictionary which we can use for scoring our review text\n",
    "df.rename(columns={\"reviewText\": \"text\"}, inplace=True)\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score\n",
    "\n",
    "# Adding the negative words to the dictionary\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)\n",
    "df[['asin','text','Bing_Liu_Score']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bing_Liu_Score'] = preprocessing.scale(df['Bing_Liu_Score'])\n",
    "df.groupby('overall').agg({'Bing_Liu_Score':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Vectorizing Text Data and Applying a Supervised Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json('reviews.json', lines=True)\n",
    "\n",
    "# Assigning a new [1,0] target class label based on the product rating\n",
    "df['sentiment'] = 0\n",
    "df.loc[df['overall'] > 3, 'sentiment'] = 1\n",
    "df.loc[df['overall'] < 3, 'sentiment'] = 0\n",
    "\n",
    "# Removing unnecessary columns to keep a simple DataFrame\n",
    "df.drop(columns=[\n",
    "    'reviewTime', 'unixReviewTime', 'overall', 'reviewerID', 'summary'],\n",
    "        inplace=True)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for preprocessing the text\n",
    "\n",
    "import re\n",
    "import html\n",
    "import pandas as pd\n",
    "import spacy    \n",
    "from spacy.tokens import Token, Span\n",
    "\n",
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text) \n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# First method that performs Tokenization and Lemmatization by re-using the blueprint from Chapter 4 \n",
    "# This can take longer to run due to the size of the dataset!\n",
    "import textacy\n",
    "import spacy\n",
    "from spacy.lang.en import STOP_WORDS as stop_words\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t.lemma_ for t in textacy.extract.words(doc,\n",
    "                                                    filter_stops = False,\n",
    "                                                    filter_punct = True,\n",
    "                                                    filter_nums = True,\n",
    "                                                    include_pos = ['ADJ', 'NOUN', 'VERB', 'ADV'],\n",
    "                                                    exclude_pos = None,\n",
    "                                                    min_freq = 1)]\n",
    "\n",
    "# def clean_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     lemmas = extract_lemmas(doc)\n",
    "#     return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data preparation\n",
    "\n",
    "df['text_orig'] = df['text'].copy()\n",
    "df['text'] = df['text'].apply(clean)\n",
    "\n",
    "# df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Remove observations that are empty after the cleaning step\n",
    "df = df[df['text'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n",
    "                                                    df['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['sentiment'])\n",
    "\n",
    "print ('Size of Training Data ', X_train.shape[0])\n",
    "print ('Size of Test Data ', X_test.shape[0])\n",
    "\n",
    "print ('Distribution of classes in Training Data :')\n",
    "print ('Positive Sentiment ', str(sum(Y_train == 1)/ len(Y_train) * 100.0))\n",
    "print ('Negative Sentiment ', str(sum(Y_train == 0)/ len(Y_train) * 100.0))\n",
    "\n",
    "print ('Distribution of classes in Testing Data :')\n",
    "print ('Positive Sentiment ', str(sum(Y_test == 1)/ len(Y_test) * 100.0))\n",
    "print ('Negative Sentiment ', str(sum(Y_test == 0)/ len(Y_test) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Text vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,1))\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Training the machine learning model\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model1 = LinearSVC(random_state=42, tol=1e-5, dual='auto')\n",
    "model1.fit(X_train_tf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Y_pred = model1.predict(X_test_tf)\n",
    "print ('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\n",
    "# print ('ROC-AUC Score - ', roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = df.sample(5)\n",
    "sample_reviews_tf = tfidf.transform(sample_reviews['text'])\n",
    "sentiment_predictions = model1.predict(sample_reviews_tf)\n",
    "sentiment_predictions = pd.DataFrame(data = sentiment_predictions,\n",
    "                                     index=sample_reviews.index,\n",
    "                                     columns=['sentiment_prediction'])\n",
    "sample_reviews = pd.concat([sample_reviews, sentiment_predictions], axis=1)\n",
    "print ('Some sample reviews with their sentiment - ')\n",
    "sample_reviews[['text_orig','sentiment_prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_scorer(text):\n",
    "    score = bing_liu_score(text)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "Y_pred_baseline = X_test.apply(baseline_scorer)\n",
    "acc_score = accuracy_score(Y_pred_baseline, Y_test)\n",
    "print (acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueprint: Using the Transfer Learning Technique and a Pretrained Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased',finetuning_task='binary')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text, tokenizer, max_seq_length, add_special_tokens=True):\n",
    "  input_ids = tokenizer.encode(text,\n",
    "                               add_special_tokens=add_special_tokens,\n",
    "                               max_length=max_seq_length,\n",
    "                               pad_to_max_length=True)\n",
    "  attention_mask = [int(id > 0) for id in input_ids]\n",
    "  assert len(input_ids) == max_seq_length\n",
    "  assert len(attention_mask) == max_seq_length\n",
    "  return (input_ids, attention_mask)\n",
    "\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "input_ids, attention_mask = get_tokens(text,\n",
    "                                       tokenizer,\n",
    "                                       max_seq_length=30,\n",
    "                                       add_special_tokens = True)\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print (text)\n",
    "print (input_tokens)\n",
    "print (input_ids)\n",
    "print (attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text_orig'],\n",
    "                                                    df['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['sentiment'])\n",
    "X_train_tokens = X_train.apply(get_tokens, args=(tokenizer, 50))\n",
    "X_test_tokens = X_test.apply(get_tokens, args=(tokenizer, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_ids_train = torch.tensor(\n",
    "    [features[0] for features in X_train_tokens.values], dtype=torch.long)\n",
    "input_mask_train = torch.tensor(\n",
    "    [features[1] for features in X_train_tokens.values], dtype=torch.long)\n",
    "label_ids_train = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "\n",
    "print (input_ids_train.shape)\n",
    "print (input_mask_train.shape)\n",
    "print (label_ids_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train,input_mask_train,label_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Model training\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "train_batch_size = 64\n",
    "num_train_epochs = 2\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=train_batch_size)\n",
    "t_total = len(train_dataloader) // num_train_epochs\n",
    "\n",
    "print (\"Num examples = \", len(train_dataset))\n",
    "print (\"Num Epochs = \", num_train_epochs)\n",
    "print (\"Total train batch size  = \", train_batch_size)\n",
    "print (\"Total optimization steps = \", t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 0\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, notebook\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "\n",
    "# Put model in 'train' mode\n",
    "model.train()\n",
    "\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = notebook.tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "        # Reset all gradients at start of every iteration\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Put the model and the input observations to GPU\n",
    "        model.to(device)\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Identify the inputs to the model\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        # Forward Pass through the model. Input -> Model -> Output\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Determine the deviation (loss)\n",
    "        loss = outputs[0]\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "        # Back-propogate the loss (automatically calculates gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Prevent exploding gradients by limiting gradients to 1.0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update the parameters and learning rate\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('../data/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model evaluation\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "test_batch_size = 64\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             sampler=test_sampler,\n",
    "                             batch_size=test_batch_size)\n",
    "\n",
    "# Load the pretrained model that was saved earlier\n",
    "# model = model.from_pretrained('/outputs')\n",
    "\n",
    "# Initialize the prediction and actual labels\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "\n",
    "# Put model in \"eval\" mode\n",
    "model.eval()\n",
    "\n",
    "for batch in notebook.tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "\n",
    "    # Put the model and the input observations to GPU\n",
    "    model.to(device)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Do not track any gradients since in 'eval' mode\n",
    "    with torch.no_grad():\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # We get loss since we provided the labels\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        # There maybe more than one batch of items in the test dataset\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids,\n",
    "                                      inputs['labels'].detach().cpu().numpy(),\n",
    "                                      axis=0)\n",
    "\n",
    "# Get final loss, predictions and accuracy\n",
    "preds = np.argmax(preds, axis=1)\n",
    "acc_score = accuracy_score(preds, out_label_ids)\n",
    "print ('Accuracy Score on Test data ', acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tahlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
