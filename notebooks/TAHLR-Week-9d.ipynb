{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAHLR Week 9d: Text Classification Algorithms\n",
    "\n",
    "Code notebook for TAHLR course at ISAW (Fall 2023) including a streamlined example of notebook 9d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # installs\n",
    "# # uncomment and install if necessary\n",
    "\n",
    "# !python -m pip install -U scikit-learn\n",
    "# !python -m pip install lime\n",
    "# !python -m pip install git+https://github.com/diyclassics/cltk_readers.git#egg=cltkreaders\n",
    "# !python -m pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from cltkreaders.grc import GreekTesseraeCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corpus readers/files\n",
    "\n",
    "GCR = GreekTesseraeCorpusReader()\n",
    "\n",
    "iliad = GCR.fileids(match='iliad')\n",
    "odyssey = GCR.fileids(match='odyssey')\n",
    "\n",
    "iliad_sents = list(GCR.sents(iliad))\n",
    "odyssey_sents = list(GCR.sents(odyssey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess texts\n",
    "\n",
    "def preprocess(text):\n",
    "    import unicodedata\n",
    "    def strip_diacritics(text):\n",
    "        # strip diacritics from greek words with function\n",
    "        stripped_text = ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "        return unicodedata.normalize('NFC', stripped_text)\n",
    "    return strip_diacritics(text)\n",
    "\n",
    "iliad_sents = [preprocess(sent) for sent in iliad_sents]\n",
    "odyssey_sents = [preprocess(sent) for sent in odyssey_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill dataframe\n",
    "\n",
    "class_names = ['iliad', 'odyssey']\n",
    "df['class'] = [0 for sent in iliad_sents] + [1 for sent in odyssey_sents]\n",
    "df['texts'] = iliad_sents + odyssey_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary info for class\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/test splits\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['texts'],\n",
    "                                                    df['class'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['class'])\n",
    "\n",
    "print('Size of Training Data ', X_train.shape[0])\n",
    "print('Size of Test Data ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df = 2, max_features=1000)),\n",
    "    ('svm', SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "print ('Accuracy Score - ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make confusion matrix\n",
    "# nb: plot_confusion_matrix as shown in *Blueprints* is deprecated; use ConfusionMatrixDisplay instead as shown below [PJB 11.3.2023]\n",
    "\n",
    "CMD = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)\n",
    "CMD.plot(cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create explainer\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change X_test to a list \n",
    "\n",
    "X_test_list = X_test.tolist()\n",
    "Y_test_list = Y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function for \"verbose\" explanation\n",
    "\n",
    "def generate_explanation(idx, class_names=class_names):\n",
    "    exp = explainer.explain_instance(X_test_list[idx], pipeline.predict_proba, num_features = 5)\n",
    "    print(f'Document id: {idx}')\n",
    "    print(f'Probability (0 = {class_names[0]}, 1 = {class_names[1]}) =', pipeline.predict_proba([X_test_list[idx]])[0,1])\n",
    "    print(f'True class: {Y_test.iloc[idx]} ({class_names[0] if Y_test_list[idx] == 0 else class_names[1]})')\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an explanation example\n",
    "\n",
    "idx = 0\n",
    "exp = generate_explanation(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show explanation as list\n",
    "\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show explanation as barplot\n",
    "\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show explanation as annotated text\n",
    "\n",
    "idx = 0\n",
    "exp = generate_explanation(idx)\n",
    "exp.show_in_notebook(text = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random explanation from test set\n",
    "\n",
    "import random\n",
    "\n",
    "for idx in random.sample(range(len(X_test)), 5):\n",
    "    exp = generate_explanation(idx)\n",
    "    exp.show_in_notebook(text = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tahlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
